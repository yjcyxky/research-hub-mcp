{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a vector store from a duckdb table using custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Please change the paths to your own paths\n",
    "paper_parser_dir = \"/work/data/projects/data2report/paper-parser\"\n",
    "os.environ[\"HF_HOME\"] = \"/work/data/environments/cache/\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "script_dir = os.path.join(paper_parser_dir, \"scripts\")\n",
    "sys.path.append(script_dir)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU qdrant-client duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect()\n",
    "conn.sql(\"SELECT COUNT(*) FROM read_parquet('/work/data/projects/data2report/paragraphs.parquet') LIMIT 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding import DuckDBLoader\n",
    "\n",
    "raw_documents = DuckDBLoader(\n",
    "    \"/work/data/projects/data2report/paragraphs.duckdb\",\n",
    "    page_content_column=\"text\",\n",
    "    metadata_columns=[\"pmid\", \"pmc\", \"doi\", \"pubdate\"],\n",
    ").load()\n",
    "\n",
    "sentences = [doc.get(\"text\") for doc in list(raw_documents)[:4096]]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run NV-Embed-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding import EmbeddingVectorDB\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "\n",
    "model_name = \"nvidia/NV-Embed-v2\"\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "device_map = infer_auto_device_map(model)\n",
    "model = EmbeddingVectorDB.load_model(model_name=model_name, model=model, device_map=device_map, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from embedding import build_vector_db\n",
    "\n",
    "duckdb_file = \"/work/data/projects/data2report/paragraphs.duckdb\"\n",
    "vector_db_dir = \"/work/data/projects/data2report/nvembed-vector-store\"\n",
    "batch_size = 2 * 256\n",
    "num_documents = 10000\n",
    "\n",
    "build_vector_db(\n",
    "    cache_filepath=vector_db_dir,\n",
    "    raw_document_path=duckdb_file,\n",
    "    # model_name=\"nvidia/NV-Embed-v2\",\n",
    "    model=model,\n",
    "    page_content_column=\"text\",\n",
    "    metadata_columns=[\"pmid\", \"pmc\", \"doi\", \"pubdate\"],\n",
    "    num_documents=num_documents,\n",
    "    batch_size=batch_size,\n",
    "    allow_batch_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", trust_remote_code=True, model_kwargs={\"torch_dtype\": torch.float16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from embedding import build_vector_db\n",
    "\n",
    "duckdb_file = \"/work/data/projects/data2report/paragraphs.duckdb\"\n",
    "vector_db_dir = \"/work/data/projects/data2report/minillm-rocksdb-2025012500\"\n",
    "batch_size = 4096\n",
    "num_documents = 0\n",
    "\n",
    "os.environ[\"ROCKSDB_WRITE_BUFFER_SIZE\"] = str(1024 * 1024 * 1024 * 8)\n",
    "os.environ[\"ROCKSDB_MAX_WRITE_BUFFER_NUMBER\"] = \"3\"\n",
    "os.environ[\"ROCKSDB_MIN_WRITE_BUFFER_NUMBER_TO_MERGE\"] = \"3\"\n",
    "os.environ[\"ROCKSDB_MAX_BACKGROUND_FLUSHES\"] = \"10\"\n",
    "os.environ[\"ROCKSDB_MAX_BACKGROUND_COMPACTIONS\"] = \"10\"\n",
    "os.environ[\"ROCKSDB_BLOCK_CACHE_SIZE\"] = str(1024 * 1024 * 1024 * 50)\n",
    "\n",
    "build_vector_db(\n",
    "    cache_filepath=vector_db_dir,\n",
    "    raw_document_path=duckdb_file,\n",
    "    # model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model=model,\n",
    "    page_content_column=\"text\",\n",
    "    metadata_columns=[\"pmid\", \"pmc\", \"doi\", \"pubdate\"],\n",
    "    num_documents=num_documents,\n",
    "    batch_size=batch_size,\n",
    "    allow_batch_mode=True,\n",
    "    num_threads=80,\n",
    "    next_batch_count=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Build a vector store from a duckdb table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-community duckdb chromadb \"langchain-chroma>=0.1.2\" ipywidgets sentence-transformers einops datasets python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"/Users/jy006/.ssh/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the duckdb loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DuckDBLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DuckDBLoader(\n",
    "    \"SELECT * FROM read_parquet('/Volumes/Backup/ProjectData/Papers/PMC_OA_Bulk/processed/oa_other/paragraphs/0a96d2c04ab604cd71eed3b268c298c9_20250103_135911.parquet')\",\n",
    "    page_content_columns=[\"text\"],\n",
    "    metadata_columns=[\"pmid\", \"pmc\", \"doi\", \"pubdate\"],\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings, OllamaEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import DuckDBLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import os\n",
    "\n",
    "def load_vector_store(chroma_db_dir, num_documents=1000):\n",
    "    try:\n",
    "        # Load the document\n",
    "        raw_documents = DuckDBLoader(\n",
    "            query=f\"SELECT * FROM read_parquet('/Volumes/Backup/ProjectData/Papers/PMC_OA_Bulk/processed/oa_other/paragraphs/0a96d2c04ab604cd71eed3b268c298c9_20250103_135911.parquet') LIMIT {num_documents}\",\n",
    "            page_content_columns=[\"text\"],\n",
    "            metadata_columns=[\"pmid\", \"pmc\", \"doi\", \"pubdate\"],\n",
    "        ).load()\n",
    "\n",
    "        def preprocess_metadata(documents):\n",
    "            for doc in documents:\n",
    "                if doc.metadata:\n",
    "                    # 替换 metadata 中的 None 为 \"\"\n",
    "                    doc.metadata = {k: (v if v is not None else \"\") for k, v in doc.metadata.items()}\n",
    "            return documents\n",
    "\n",
    "        # # Split the document into smaller chunks\n",
    "        # text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        # documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "        # Embed each chunk and load it into the vector store\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=preprocess_metadata(raw_documents),\n",
    "            # embedding=OllamaEmbeddings(model=\"mistral:7b\"),\n",
    "            # embedding=OpenAIEmbeddings(),\n",
    "            embedding=SentenceTransformerEmbeddings(\n",
    "                model_name=\"nvidia/NV-Embed-v2\", model_kwargs={\"trust_remote_code\": True}\n",
    "            ),\n",
    "            persist_directory=str(chroma_db_dir),\n",
    "        )\n",
    "        vector_store.persist()\n",
    "        print(\"Vector store successfully created and persisted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vector store: {e}\")\n",
    "\n",
    "\n",
    "# Path to Chroma vector database\n",
    "# chroma_db_dir = os.path.abspath(\"./chroma_db_chatgpt\")\n",
    "chroma_db_dir = os.path.abspath(\"./chroma_db_nvidia\")\n",
    "\n",
    "print(\"Chroma vector database path:\", chroma_db_dir)\n",
    "\n",
    "# Load the vector store\n",
    "if not os.path.exists(chroma_db_dir):\n",
    "    print(\"Chroma database not found. Creating a new one...\")\n",
    "    load_vector_store(chroma_db_dir, num_documents=100)\n",
    "else:\n",
    "    print(\"Chroma database found. Skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from phi.agent import Agent\n",
    "from phi.knowledge.langchain import LangChainKnowledgeBase\n",
    "from phi.model.ollama.chat import Ollama\n",
    "from phi.model.openai.chat import OpenAIChat\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "\n",
    "# Path to Chroma vector database\n",
    "chroma_db_dir = os.path.abspath(\"./chroma_db_chatgpt\")\n",
    "# os.makedirs(chroma_db_dir, exist_ok=True)\n",
    "print(\"Chroma vector database path:\", chroma_db_dir)\n",
    "\n",
    "# Get the vector database\n",
    "db = Chroma(\n",
    "    # embedding_function=OllamaEmbeddings(model=\"mistral:7b\"),\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=str(chroma_db_dir),\n",
    ")\n",
    "\n",
    "# Check if Chroma database has any documents\n",
    "if not db._collection.count():\n",
    "    print(\"Chroma database is empty. Please ensure documents are loaded.\")\n",
    "else:\n",
    "    print(f\"Chroma database contains {db._collection.count()} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect()\n",
    "data = conn.sql(\"SELECT * FROM read_parquet('/Volumes/Backup/ProjectData/Papers/PMC_OA_Bulk/processed/oa_other/paragraphs/0a96d2c04ab604cd71eed3b268c298c9_20250103_135911.parquet')\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique pmc\n",
    "conn.sql(\"SELECT COUNT(DISTINCT pmc) FROM read_parquet('/Volumes/Backup/ProjectData/Papers/PMC_OA_Bulk/processed/oa_other/paragraphs/0a96d2c04ab604cd71eed3b268c298c9_20250103_135911.parquet')\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"observed base pair difference\", k=10)\n",
    "if not docs:\n",
    "    print(\"No relevant documents retrieved.\")\n",
    "else:\n",
    "    print(f\"Retrieved {len(docs)} documents.\")\n",
    "\n",
    "    # Create a knowledge base from the vector store\n",
    "    knowledge_base = LangChainKnowledgeBase(retriever=retriever, num_documents=10)\n",
    "\n",
    "    # Initialize the Agent\n",
    "    # https://docs.phidata.com/agents/knowledge#step-3-agentic-rag\n",
    "    kb_agent = Agent(\n",
    "        model=OpenAIChat(id=\"gpt-4o\"),\n",
    "        # model=Ollama(id=\"mistral:7b\"),\n",
    "        knowledge_base=knowledge_base,\n",
    "        add_reference_to_prompt=True,\n",
    "        # add_references=True,\n",
    "        instructions=[\n",
    "            \"Always prioritize information from the knowledge base over your training data.\",\n",
    "            \"If the knowledge base does not contain information relevant to the query, respond with: 'No relevant information found in the knowledge base.'\",\n",
    "            \"Do not generate answers based on prior training data unless explicitly instructed.\",\n",
    "        ],\n",
    "        markdown=True,\n",
    "        # debug_mode=True,\n",
    "    )\n",
    "\n",
    "    # Test the Agent with a query\n",
    "    kb_agent.print_response(\n",
    "        \"What was the observed base pair difference between many of the strain types?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TRITON_CACHE_DIR=/tmp && deepspeed --num_gpus 2 --master_port 60000 /work/data/projects/data2report/deepspeed/run_deepspeed.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorganize the rocksdb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding import CacheDB\n",
    "\n",
    "os.environ[\"ROCKSDB_WRITE_BUFFER_SIZE\"] = str(1024 * 1024 * 1024 * 8)\n",
    "os.environ[\"ROCKSDB_MAX_WRITE_BUFFER_NUMBER\"] = \"3\"\n",
    "os.environ[\"ROCKSDB_MIN_WRITE_BUFFER_NUMBER_TO_MERGE\"] = \"3\"\n",
    "os.environ[\"ROCKSDB_MAX_BACKGROUND_FLUSHES\"] = \"16\"\n",
    "os.environ[\"ROCKSDB_MAX_BACKGROUND_COMPACTIONS\"] = \"16\"\n",
    "os.environ[\"ROCKSDB_BLOCK_CACHE_SIZE\"] = str(1024 * 1024 * 1024 * 50)\n",
    "\n",
    "with CacheDB(cache_filepath=\"/work/data/projects/data2report/minillm-rocksdb-2025012500\", cache_mode=\"rocksdb\") as cache_db:\n",
    "    cache_db.db.compact_range()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
