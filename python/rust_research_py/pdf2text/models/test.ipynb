{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/exporters/onnx/__main__.py\", line 258, in main_export\n",
      "    task = TasksManager.infer_task_from_model(model_name_or_path)\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/exporters/tasks.py\", line 1747, in infer_task_from_model\n",
      "    inferred_task_name = cls._infer_task_from_model_name_or_path(\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/exporters/tasks.py\", line 1710, in _infer_task_from_model_name_or_path\n",
      "    raise KeyError(f\"Could not find the proper task name for the model {model_name_or_path}.\")\n",
      "KeyError: 'Could not find the proper task name for the model nvidia/NV-Embed-v2.'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/bin/optimum-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/commands/optimum_cli.py\", line 208, in main\n",
      "    service.run()\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/commands/export/onnx.py\", line 265, in run\n",
      "    main_export(\n",
      "  File \"/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/site-packages/optimum/exporters/onnx/__main__.py\", line 260, in main_export\n",
      "    raise KeyError(\n",
      "KeyError: \"The task could not be automatically inferred. Please provide the argument --task with the relevant task from depth-estimation, text2text-generation, image-classification, semantic-segmentation, zero-shot-object-detection, image-segmentation, masked-im, question-answering, feature-extraction, text-generation, text-classification, fill-mask, audio-classification, audio-xvector, sentence-similarity, zero-shot-image-classification, automatic-speech-recognition, token-classification, object-detection, multiple-choice, text-to-audio, image-to-text, audio-frame-classification, image-to-image, mask-generation. Detailed error: 'Could not find the proper task name for the model nvidia/NV-Embed-v2.'\"\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export onnx --model 'nvidia/NV-Embed-v2' nv-embed-v2-openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01b2811459a4ff3995db2be8fdd863e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NVEmbedModel(\n",
       "  (latent_attention_model): LatentAttentionModel(\n",
       "    (cross_attend_blocks): ModuleList(\n",
       "      (0): PreNorm(\n",
       "        (fn): Attention(\n",
       "          (to_q): Linear(in_features=4096, out_features=32768, bias=False)\n",
       "          (to_kv): Linear(in_features=4096, out_features=65536, bias=False)\n",
       "          (to_out): Linear(in_features=32768, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_context): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): PreNorm(\n",
       "        (fn): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=4096, out_features=32768, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding_model): BidirectionalMistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"nvidia/NV-Embed-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepspeed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 减少显存占用，可以使用半精度\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 如果显卡支持 bfloat16 也可以改成 torch.bfloat16\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepspeed'"
     ]
    }
   ],
   "source": [
    "import deepspeed\n",
    "\n",
    "# 减少显存占用，可以使用半精度\n",
    "# 如果显卡支持 bfloat16 也可以改成 torch.bfloat16\n",
    "dtype = torch.float16\n",
    "model = model.half()\n",
    "\n",
    "# mp_size=1 表示不做张量并行，适合单卡或仅想用DeepSpeed优化kernel的情况\n",
    "# 如果有多张GPU并想做模型并行，可将 mp_size 设为 GPU 数量。\n",
    "engine = deepspeed.init_inference(\n",
    "    model=model,\n",
    "    mp_size=1,\n",
    "    replace_method=\"auto\",        # DeepSpeed会自动替换支持的层\n",
    "    replace_with_kernel=True      # 使用已优化的自定义kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy006/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/5130cf1daf847c1bacee854a6ef1ca939e747fb2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n",
      "/Users/jy006/miniconda3/envs/paper-parser/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0071, -0.0291,  0.0052,  ..., -0.0105,  0.0044,  0.0002]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = engine.module.encode([\n",
    "        \"PD-L1 expression in cancer patients receiving anti PD-1\\/PD-L1 antibodies: A systematic review and meta-analysis\\nBackground: Despite the success of immunotherapy directed at inhibiting of programmed death-1 (PD-1)\\/PD-ligand (L)1 signaling, it is not established whether PD-L1 expression correlates with the clinical response and outcome in different tumors. The present meta-analysis investigates whether the PD-L1 status, detected by immunohistochemistry, is associated with clinical response and mortality in patients treated with anti-PD-1\\/PD-L1 therapy. Methods: A systematic literature search and quantitative analysis were planned, conducted and reported following CONSORT and QUORUM checklists, up to December 2015, to identify clinical trials with information on cancer outcome by PD-L1 immunohistochemical expression in tumor tissues. We used random effects models to estimate Summary Objective Response Rates (SORRs) and Summary Odd Ratio (SOR) for the comparison of PD-L1 positive and negative patients. Results: We summarized 20 trials carried out in metastatic melanoma (MM), non-small cell lung cancer (NSCLC), and renal cell carcinoma (RCC) patients receiving anti-PD-1\\/PD-L1 antibodies (4230 MM, 1417 NSCLC and 312 RCC patients). Positive PD-L1 MM patients showed a significant decrease (53%) in the risk of mortality vs. negative cases with no heterogeneity. Furthermore, SORRs were 45% and 27% in PD-L1 positive and negative patients, respectively, and SOR indicates a significant difference in term of responses: 2.14 (95% CI: 1.65, 2.77), with low between-study heterogeneity (I 2 = 35%). Furthermore, results from randomized clinical trials on MM showed that PD-L1 expression is significantly associated with greater clinical response rates to anti-PD1 treatments (SOR 1.89; 95%CI: 1.35, 2.64) but not to other treatments (SOR 0.96; 95%CI: 0.5, 1.87). In non-squamous NSCLC SORRs were 29% and 11% in PD-L1 positive and negative patients, respectively, and SOR indicates a significant difference between responses: 3.78 (1.54, 9.24), with no between-study heterogeneity. Squamous NSCLC and RCC did not show any significant difference in response according to the PD-L1 status. Conclusion: PD-L1 expression is significantly associated with mortality and clinical response to anti-PD-1\\/PD-L1 antibodies in MM patients and with clinical response in patients with non-squamous NSCLC.\"\n",
    "    ], instruction=\"\", max_length=32768)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
